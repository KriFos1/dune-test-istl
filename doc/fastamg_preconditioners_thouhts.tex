\documentclass{article}

\usepackage{algorithm}
\usepackage{algpseudocode}

\begin{document}

\section{Defect Calculation}

The defect of a system given a solution $x^k$ is defined as 
\begin{equation}
d=b-Ax^k
\end{equation}
This can be calculated with the following simple algorithm:
\begin{algorithm}
\caption{Defect Calculation}
\label{alg:def}
\begin{algorithmic}[1]
\State $d\gets b$
\For {$i=0,\dots ,n$}
  \For {$j=0,\dots ,n$}
    \State $d_i\gets d_i-a_{ij}x_j$ \label{line:crux}
  \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

Assuming that A is symmetric this can also be calculated as in algorithm~\ref{alg:defalt}. The inner and outer loop have therefore been switched and $a_{ij}=a_{ji}$ applied.

\begin{algorithm}
\caption{Defect Calculation for symmetric matrices $A$}
\label{alg:defalt}
\begin{algorithmic}[1]
\State $d\gets b$
\For {$i=0,\dots ,n$}
  \For {$j=0,\dots ,n$}
    \State $d_j\gets d_j-a_{ij}x_i$ \label{line:crux2}
  \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\section{Gauss-Seidel Preconditioner}

see Emans.

\section{Jacobi Preconditioner}

A Jacobi Preconditioner:

\begin{equation}
x_i^{k+1}=a_{ii}^{-1}\left(b_i-\sum_{j\neq i}a_{ij}x_j^k\right)
\end{equation}

this is done algorithmically with
\begin{algorithm}
\caption{Jacobi Preconditioner}
\label{alg:jac}
\begin{algorithmic}[1]
\State $x^{old}\gets x$
\For {$i=0,\dots ,n-1$ matrix rows}
  \State $r\gets b_i$
  \For {$j\neq i$ matrix columns}
    \State $r \gets r - a_{ij}x_j^{old}$
  \EndFor
  \State $x_i \gets r/a_{ii}$
\EndFor
\end{algorithmic}
\end{algorithm}

The challenge is to combine the computation of defect and \ref{alg:jac} into one algorithm with one outer loop over the matrix rows, to improve memory access. This is not possible without modification as the entries of the new $x$ needed in line~\ref{line:crux} are not yet available. However, you can use algorithm~\ref{alg:defalt} instead. These algorithms may then be combined into algorithm~\ref{alg:jacnew}.
\begin{algorithm}
\caption{Jacobi Preconditioner with Simulataneous Defect Calculation}
\label{alg:jacnew}
\begin{algorithmic}[1]
\State $x^{old}\gets x$
\State $d\gets b$
\For {$i=0,\dots ,n-1$ matrix rows}
  \State $r\gets b_i$
  \For {$j\neq i$ matrix columns}
    \State $r \gets r - a_{ij}x_j^{old}$
  \EndFor
  \State $x_i \gets r/a_{ii}$
  \For {$j=0,\dots ,n$}
    \State $d_j\gets d_j-a_{ij}x_i$
  \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

For further enhancements when doing multiple steps of Jacobi preconditioning the algorithm may be told whether this is the first or last step. The first step is quite trivial due to $x^o=0$, the defect is only to be computed in the last iteration. This results in algorithm~\ref{alg:full}, which is only valid for the forward smmothing step, in the backward step neither a defect has to be calculated, nor $x^0=0$. Thus the backwards step looks exaclty like algorithm~\ref{alg:jac}.

\begin{algorithm}
\caption{The full algorithm}
\label{alg:full}
\begin{algorithmic}[1]
\If {$last$}
  \State $d\gets b$
\EndIf
\If {$first$}
  \For {$i=0,\dots ,n-1$}
    \State $x_i\gets b_i/a_{ii}$
  \EndFor
  \If {$last$}
    \For {$j=0,\dots ,n-1$}
      \State $d_j\gets d_j - a_{ij}x_{i}$
    \EndFor
  \EndIf
\Else
  \State $x^{old}\gets x$
  \For {$i=0,\dots ,n-1$}
    \State $r\gets b_i$
    \For {$j\neq i$}
      \State $r\gets r-a_{ij}x^{old}_j$
    \EndFor
    \State $x_i\gets r/a_{ii}$
    \If {$last$}
      \For {$j=0,\dots ,n-1$}
        \State $d_j\gets d_j - a_{ij}x_{i}$
      \EndFor
    \EndIf
  \EndFor
\EndIf
\end{algorithmic}
\end{algorithm}

\section{ILU(n) Preconditioner}

ILU(n) calculates a LU decomposition limited to a certain sparsity spattern. The computation of the decomposition is not subject to optimization here and the implementation from dune/istl/ilu.hh can be taken. The forward/backward substitution is though, algorithm~\ref{alg:ilu} reflects how the computation is done in above header. Note that the matrices $L$ and $U$ are stored within a single matrix and line~\ref{line:lii} implies $l_{ii}=1$.

TODO das r im vorwaertseinsetzen ist eigentlich unnoetig, trotzdem schneller????

\begin{algorithm}
\caption{ILU(n) forward/backward substitution as in dune/istl/ilu.hh}
\label{alg:ilu}
\begin{algorithmic}
\For {$i=0,\dots ,n-1$}
  \State $r\gets b_i$
  \For {$j<i$}
    \State $r\gets r-l_{ij}x_j$
  \EndFor
  \State $x_i\gets r$ \label{line:lii}
\EndFor
\For {$i=n-1,\dots ,0$}
  \State $r\gets x_i$
  \For {$j>i$}
    \State $r\gets r-u_{ij}x_j$
  \EndFor
  \State $x_i\gets r/u_{ii}$
\EndFor
\end{algorithmic}
\end{algorithm}

Once again symmetry on A is assumed to calculate the defect inside the last loop. The final result is algorithm~\ref{alg:ilunew}. A special treatment as previously seen is not needed here, as this preconditioner isnt applied iteratively and there is no savings from $x$ is being initialized to $0$.

\begin{algorithm}
\caption{ILU(n) forward/backward substitution with defect}
\label{alg:ilunew}
\begin{algorithmic}
\For {$i=0,\dots ,n-1$}
  \State $x_i\gets b_i$
  \For {$j<i$}
    \State $x_i\gets x_i-l_{ij}x_j$
  \EndFor
\EndFor
\For {$i=n-1,\dots ,0$}
  \For {$j>i$}
    \State $x_i\gets x_i-u_{ij}x_j$
  \EndFor
  \State $x_i\gets x_i/u_{ii}$
  \For {$j=0,\dots ,n$}
    \State $d_j\gets d_j-a_{ij}x_i$
  \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}
\end{document}